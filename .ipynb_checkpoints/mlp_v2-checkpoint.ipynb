{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib qt\n",
    "\n",
    "class MLP:\n",
    "    \"\"\"Class defining a neural network using back propagation\"\"\"\n",
    "    \n",
    "    def __init__(self, layers, W = None, B = None):\n",
    "        \"\"\"layers is initialized as a list(input_layer, ...hidden_layers..., output_layers)\"\"\"\n",
    "        self.n_layers = len(layers) - 1\n",
    "        self.layers = layers\n",
    "        if W is None and B is None:\n",
    "            self.initialize_weights()\n",
    "        else:\n",
    "            self.weights = W\n",
    "            self.biases = B\n",
    "            \n",
    "        self.actual_output = 0\n",
    "        \n",
    "    def initialize_weights(self):\n",
    "        \"\"\"generate weights and biases for hidden layers \n",
    "        in a standard gaussian distribution  mean 0 deviation 1\"\"\"\n",
    "        self.biases = [np.random.randn(1, y) for y in self.layers[1:]]\n",
    "        self.weights = [np.random.randn(y, x) for x, y in zip(self.layers[:-1], self.layers[1:])]\n",
    "    \n",
    "    def sigmoid(self, x):\n",
    "        \"\"\"The sigmoid function\"\"\"\n",
    "        return 1 / (1 + np.exp(-x))    \n",
    "    \n",
    "    def derivative(self, sig_x):\n",
    "        \"\"\"return the derivative of sig_x\"\"\"\n",
    "        return sig_x*(1 - sig_x)\n",
    "    \n",
    "    def net_error(self, tar, out):\n",
    "        \"\"\"compute mean square error for network\"\"\"\n",
    "        err = np.mean(np.square(tar - out))\n",
    "        # or (1/2)*np.sum(np.power(tar - out, 2))???\n",
    "        \n",
    "        return err\n",
    "    \n",
    "    def graph_error(self, train_array, test_array = None):\n",
    "        \"\"\"display graphical error\"\"\"\n",
    "        plt.figure(0)\n",
    "        plt.xlabel(\"Epochs\")\n",
    "        plt.ylabel(\"Error\")\n",
    "        plt.title(\"Back-Propagation algortihm\")\n",
    "        plt.plot(train_array, label=\"training error\")\n",
    "        if test_array is not None: \n",
    "            xs = np.arange(len(test_array))\n",
    "            t_array = np.array(test_array).astype(np.double)\n",
    "            ta_mask = np.isfinite(t_array)\n",
    "            plt.plot(xs[ta_mask], t_array[ta_mask], label=\"testing error\")\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "    \n",
    "    def feed_forward(self, input):\n",
    "        \"\"\"the feed forward function\"\"\"\n",
    "        self.layers_output = []\n",
    "        \n",
    "        for index in range(self.n_layers):\n",
    "            if index == 0:\n",
    "                z = np.dot(input, self.weights[index].T) + self.biases[index]\n",
    "                self.layers_output.append(self.sigmoid(z))\n",
    "            else: \n",
    "                z = np.dot(self.layers_output[index -1], self.weights[index].T) + self.biases[index]\n",
    "                self.layers_output.append(self.sigmoid(z))\n",
    "        \n",
    "        return self.layers_output[-1][0]\n",
    "    \n",
    "    def back_propagation(self, input, target, trainingRate = 0.2):\n",
    "        \"\"\"the back_propagation function\"\"\"\n",
    "        l_errors = []\n",
    "        #feed forward\n",
    "        actual_error = self.net_error(target, self.feed_forward(input)) \n",
    "        \n",
    "        # compute l_errors \n",
    "        for index in reversed(range(self.n_layers)):\n",
    "            sig_prim = self.derivative(self.layers_output[index])\n",
    "            if index == self.n_layers - 1:\n",
    "                \n",
    "                output_delta = -(target - self.layers_output[index])\n",
    "                l_errors.append(output_delta*sig_prim)\n",
    "            else:\n",
    "                hidden_delta = np.dot(l_errors[-1], self.weights[index+1])*sig_prim\n",
    "                l_errors.append(hidden_delta)\n",
    "        \n",
    "        l_errors = l_errors[::-1]\n",
    "        self.layers_output.insert(0, input)\n",
    "        \n",
    "        # new biases and weights\n",
    "        for index in range(self.n_layers ):    \n",
    "            multiply = np.multiply(l_errors[index].T, self.layers_output[index])            \n",
    "            self.weights[index] = self.weights[index] - trainingRate*multiply\n",
    "            self.biases[index] = self.biases[index] - trainingRate*l_errors[index]\n",
    "        \n",
    "        #return the error calculated with the precedent weights\n",
    "        return actual_error\n",
    "    \n",
    "    def train(self, epochs, trainingRate, training_set, testing_set, interval = 100):\n",
    "        training_err = []\n",
    "        testing_err = []\n",
    "        \n",
    "        t_input = training_set['input']\n",
    "        t_output = training_set['output']\n",
    "        \n",
    "        test_input = testing_set['input']\n",
    "        test_output = testing_set['output']\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            #print('Epoch {}/{}'.format(epoch +1, epochs))\n",
    "            count = 0\n",
    "            err = 0\n",
    "            \n",
    "            for x in t_input:\n",
    "                # back propagation and net error\n",
    "                err += self.back_propagation(x, t_output[count], trainingRate)\n",
    "                count += 1               \n",
    "            #print('loss = {}'.format(err/t_input.shape[0]))\n",
    "            training_err.append(err/t_input.shape[0])\n",
    "            \n",
    "            if not epoch%interval:\n",
    "                predict = []\n",
    "                test_err = 0\n",
    "                test_count = 0\n",
    "                for x_test in test_input:\n",
    "                    a = self.predict(x_test)\n",
    "                    test_err += self.net_error(test_output[test_count], a) \n",
    "                    test_count += 1\n",
    "                \n",
    "                testing_err.append(test_err/test_input.shape[0])\n",
    "            else:\n",
    "                testing_err.append(None)\n",
    "                \n",
    "        return training_err, testing_err\n",
    "    \n",
    "    def predict(self, input):\n",
    "        \"\"\"Return predicted values of an input\"\"\"\n",
    "        prediction = 0\n",
    "        \n",
    "        for index in range(self.n_layers):\n",
    "            if index == 0:\n",
    "                z = np.dot(input, self.weights[index].T) + self.biases[index]\n",
    "                prediction = self.sigmoid(z)\n",
    "            else: \n",
    "                z = np.dot(prediction, self.weights[index].T) + self.biases[index]\n",
    "                prediction = self.sigmoid(z)\n",
    "        \n",
    "        return prediction\n",
    "        \n",
    "    def main(self, epochs, trainingRate, input, target):\n",
    "        err_vector = []\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            count = 0\n",
    "            err = 0\n",
    "            \n",
    "            for x in input:\n",
    "                \n",
    "                #back propagation\n",
    "                my_err = self.back_propagation(x, target[count], trainingRate)\n",
    "                \n",
    "                #net error\n",
    "                \n",
    "                err+= self.net_error(target[count], self.layers_output[-1][0])\n",
    "\n",
    "                count +=1\n",
    "            err_vector.append(err / input.shape[0])\n",
    "            \n",
    "        #graph error\n",
    "        self.graph_error(err_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"XOR learning\"\"\"\n",
    "\n",
    "my_mlp = MLP([2, 2, 1])\n",
    "my_mlp.main(1000, 0.5, np.array([[0,0],[0,1],[1,0],[1,1]]), np.array([[1],[1],[0],[0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Iris dataset learning\"\"\"\n",
    "\n",
    "#get the iris dataset\n",
    "def get_dataset():\n",
    "    f = open(\"./iris_data/iris.data\")\n",
    "    \n",
    "    lines = f.readlines()\n",
    "    f.close()\n",
    "    \n",
    "    np.random.shuffle(lines)\n",
    "    input = []\n",
    "    output = []\n",
    "    training_set = {}\n",
    "    testing_set = {}\n",
    "    for line in lines:\n",
    "        if(len(line) > 1):\n",
    "            x_0, x_1, x_2, x_3, y = line.replace('\\n','').split(',')\n",
    "            input.append([float(x_0),float(x_1),float(x_2),float(x_3)])\n",
    "            \n",
    "            if y == 'Iris-setosa':\n",
    "                output.append([1,0,0])\n",
    "            if y == 'Iris-versicolor':\n",
    "                output.append([0,1,0])\n",
    "            if y == 'Iris-virginica':\n",
    "                output.append([0,0,1])\n",
    "            \n",
    "            training_set = {\n",
    "                'input': np.array(input[0:120]),\n",
    "                'output': np.array(output[0:120])\n",
    "            }\n",
    "            \n",
    "            testing_set =  {\n",
    "                'input': np.array(input[121:151]),\n",
    "                'output': np.array(output[121:151])\n",
    "            }\n",
    "            \n",
    "    return (training_set, testing_set)\n",
    "    \n",
    "\n",
    "my_mlp = MLP([4, 2, 3, 3])\n",
    "\n",
    "training_set, testing_set = get_dataset()\n",
    "\n",
    "training_err, testing_err = my_mlp.train(1000, 0.05, training_set, testing_set, 10)\n",
    "\n",
    "\n",
    "my_mlp.graph_error(training_err, testing_err)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
