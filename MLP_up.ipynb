{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "%matplotlib qt\n",
    "\n",
    "#Back-propagation\n",
    "def back_propagation(x, tar, weights, bias, layers):\n",
    "    \n",
    "    n_layers = len(layers)\n",
    "    # output layer error\n",
    "    L_layer = layers[n_layers - 1]\n",
    "    \n",
    "    #L_error value is (0.5(sigmoid(s_1) - target)^2)'\n",
    "    # the derivative value: (1-sigmoid^2(s))(sigmoid(s) - tar)\n",
    "    # -(tar - a_L)*a_L*(1-a_L)\n",
    "    L_error = -(tar - L_layer)*L_layer*(1 - L_layer)\n",
    "    \n",
    "    \n",
    "    # hidden layers errors\n",
    "    # l_errors[layer -1] = l_sum*layers[layer -1 ]*(1- layers[layer -1])\n",
    "    l_errors = [0 for i in range(n_layers)]\n",
    "    l_errors[n_layers -1] = L_error\n",
    "    \n",
    "    for layer in range(n_layers - 1, 0, -1):\n",
    "        l_weights = weights[layer]\n",
    "        \n",
    "        #sumarize\n",
    "        l_sum = []\n",
    "        for weight in l_weights.T:\n",
    "             l_sum.append(np.sum(weight*l_errors[layer]))\n",
    "        l_sum = np.array(l_sum)\n",
    "        \n",
    "        \n",
    "        # compute the previous l_error vector\n",
    "        l_errors[layer -1] = l_sum*layers[layer -1 ]*(1- layers[layer -1])\n",
    "        \n",
    "    # New weights and bias    \n",
    "    my_layers = copy.deepcopy(layers)\n",
    "    my_layers.insert(0, x)\n",
    "    \n",
    "    n_weights = [0]*(len(my_layers) -1 )\n",
    "    n_bias = [0]*(len(my_layers) - 1)\n",
    "    for i in range(len(n_weights)):\n",
    "        non_reshaped_l_errors = l_errors[i]\n",
    "        l_errors[i] = np.reshape(l_errors[i], (len(l_errors[i]), 1))\n",
    "        my_layers[i] = np.reshape(my_layers[i],(len(my_layers[i]),1))\n",
    "        n_weights[i] = weights[i] - alpha*np.multiply(l_errors[i], my_layers[i].T)\n",
    "        n_bias[i] = bias[i] - alpha*non_reshaped_l_errors\n",
    "        \n",
    "    return (n_weights, n_bias)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "#feed forward\n",
    "\n",
    "x: input vector\n",
    "layers: [nb_node_layer_1, nb_node_layer_2, ...]\n",
    "weights: [[w_layer_1:[w_node_1],[w_node_2]], [w_layer_2:[w_node_1],[w_node_2]]]\n",
    "bias: [b_layer_1, b_layer_2]\n",
    "\"\"\"\n",
    "def feed_forward(x, layers, weights, bias):\n",
    "    nb_layers = len(layers)\n",
    "    a= []\n",
    "    z = np.dot(x, weights[0].T) + bias[0]\n",
    "    a.append(sigmoid(z))\n",
    "    \n",
    "    for layer in range(1, len(layers)):\n",
    "        multiply = np.dot(a[layer -1], weights[layer].T)\n",
    "        z =  multiply + bias[layer]\n",
    "        a.append(np.array(sigmoid(z)))     \n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sigmoid function\n",
    "def sigmoid(x):\n",
    "    sig = 1 / (1+ np.exp(-x))\n",
    "    \n",
    "    return (sig)\n",
    "\n",
    "#Network error\n",
    "def net_error(tar, out):\n",
    "    err = 0.5 * np.power(tar - out, 2)\n",
    "    \n",
    "    return (err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "initialize the weights matrice with random values on a normal distribution\n",
    "\"\"\"\n",
    "def init_weights(x, layers):\n",
    "    weights = []\n",
    "    weights.append(np.random.normal(0,0.1, (layers[0], len(x))))\n",
    "    \n",
    "    \n",
    "    for layer in range(1, len(layers)):\n",
    "        weights.append(np.random.normal(0,0.1, (layers[layer], layers[layer -1])))\n",
    "    \n",
    "    return (weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph error\n",
    "def graph_error(err_vector):\n",
    "    plt.figure(0)\n",
    "    plt.plot(err_vector)\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Error\")\n",
    "    plt.title(\"Back-Propagation algortihm\")\n",
    "    plt.show()\n",
    "\n",
    "# Testing patterns\n",
    "def testing_patterns(X, t, layers, weights, bias):\n",
    "    print('===== MLP result ===')\n",
    "    print('Pat:   t:     out:')\n",
    "    count = 0\n",
    "    for x in X:\n",
    "        a = feed_forward(x, layers, weights, bias)\n",
    "        a_N = a[len(a) -1][0]\n",
    "        print('{}. {} ---- {} ----> {:.3f}'.format(count, x, t[count], float(a_N)))\n",
    "        count +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "will start\n",
      "===== MLP result ===\n",
      "Pat:   t:     out:\n",
      "0. [0 0] ---- 1 ----> 0.989\n",
      "1. [0 1] ---- 1 ----> 0.999\n",
      "2. [1 0] ---- 0 ----> 0.018\n",
      "3. [1 1] ---- 1 ----> 0.991\n"
     ]
    }
   ],
   "source": [
    "def main_1():\n",
    "    X = np.array([[0,0], [0,1], [1,0], [1,1]])\n",
    "    tar = np.array([1,1,0,1])\n",
    "\n",
    "    layers = [2, 1]\n",
    "    alpha = 0.5\n",
    "    epochs = 8000\n",
    "\n",
    "    bias = [np.random.normal(0,0.1, layers[i]) for i in range(len(layers))]\n",
    "    weights = init_weights(X[0], layers)\n",
    "\n",
    "    err_vector = []\n",
    "\n",
    "    print(\"will start\")\n",
    "    for epoch in range(epochs):\n",
    "        count = 0\n",
    "        err = 0\n",
    "\n",
    "        for my_x in X:\n",
    "            #feed_forward    \n",
    "            a = feed_forward(my_x, layers, weights, bias)\n",
    "\n",
    "\n",
    "            #Net error\n",
    "            err += net_error(tar[count], a[len(a) -1])\n",
    "\n",
    "            #back propagation\n",
    "            weights, bias = back_propagation(my_x, tar[count], weights, bias, a)\n",
    "\n",
    "            count +=1\n",
    "\n",
    "        err_vector.append(err / X.shape[0])\n",
    "\n",
    "    #graph error\n",
    "    graph_error(err_vector)\n",
    "\n",
    "    testing_patterns(X, tar, layers, weights, bias)\n",
    "    \n",
    "\n",
    "from iris_data.convert import get_dataset\n",
    "def main_2():\n",
    "    dataset = get_dataset()\n",
    "    \n",
    "    X = np.array(dataset['input'])\n",
    "    tar = np.array(dataset['output']) \n",
    "    \n",
    "    layers = [5,10, 1]\n",
    "    alpha = 0.5\n",
    "    epochs = 500\n",
    "\n",
    "    bias = [np.random.normal(0,0.1, layers[i]) for i in range(len(layers))]\n",
    "    weights = init_weights(X[0], layers)\n",
    "\n",
    "    err_vector = []\n",
    "\n",
    "    print(\"will start\")\n",
    "    for epoch in range(epochs):\n",
    "        count = 0\n",
    "        err = 0\n",
    "\n",
    "        for my_x in X:\n",
    "            #feed_forward    \n",
    "            a = feed_forward(my_x, layers, weights, bias)\n",
    "\n",
    "\n",
    "            #Net error\n",
    "            err += net_error(tar[count], a[len(a) -1])\n",
    "\n",
    "            #back propagation\n",
    "            weights, bias = back_propagation(my_x, tar[count], weights, bias, a)\n",
    "\n",
    "            count +=1\n",
    "\n",
    "        err_vector.append(err / X.shape[0])\n",
    "\n",
    "    #graph error\n",
    "    graph_error(err_vector)\n",
    "    \n",
    "    \n",
    "    #testing patterns\n",
    "    testing_patterns(X, tar, layers, weights, bias)\n",
    "    \n",
    "\n",
    "main_1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
