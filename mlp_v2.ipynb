{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib qt\n",
    "\n",
    "class MLP:\n",
    "    \"\"\"Class defining a neural network using back propagation\"\"\"\n",
    "    \n",
    "    def __init__(self, layers):\n",
    "        \"\"\"layers is initialized as a list(input_layer, ...hidden_layers..., output_layers)\"\"\"\n",
    "        self.n_layers = len(layers) - 1\n",
    "        self.layers = layers\n",
    "        self.initialize_weights()\n",
    "        self.actual_output = 0\n",
    "        \n",
    "    def initialize_weights(self):\n",
    "        \"\"\"generate weights and biases for hidden layers \n",
    "        in a standard gaussian distribution  mean 0 deviation 1\"\"\"\n",
    "        self.biases = [np.random.randn(1, y) for y in self.layers[1:]]\n",
    "        self.weights = [np.random.randn(y, x) for x, y in zip(self.layers[:-1], self.layers[1:])]\n",
    "    \n",
    "    def sigmoid(self, x):\n",
    "        \"\"\"The sigmoid function\"\"\"\n",
    "        return 1 / (1 + np.exp(-x))    \n",
    "    \n",
    "    def derivative(self, sig_x):\n",
    "        \"\"\"return the derivative of sig_x\"\"\"\n",
    "        return sig_x*(1 - sig_x)\n",
    "    \n",
    "    def net_error(self, tar, out):\n",
    "        \"\"\"compute the network error\"\"\"\n",
    "        err = 0.5*np.power(tar - out, 2)\n",
    "        \n",
    "        return err\n",
    "    \n",
    "    def graph_error(self, err_vector):\n",
    "        \"\"\"display graphical error\"\"\"\n",
    "        plt.figure(0)\n",
    "        plt.plot(err_vector)\n",
    "        plt.xlabel(\"Epochs\")\n",
    "        plt.ylabel(\"Error\")\n",
    "        plt.title(\"Back-Propagation algortihm\")\n",
    "        plt.show()\n",
    "    \n",
    "    def testing_patterns(self, input, target):\n",
    "        \"\"\"return the response for the patterns\"\"\"\n",
    "        print('====== MLP result ======')\n",
    "        print('Pat:    t:    out:')\n",
    "        count = 0\n",
    "        for i in input:\n",
    "            output = self.feed_forward(i)[-1][0]\n",
    "            if not hasattr(target[count], '__len__'):\n",
    "                print('{}. {} ---- {} ----> {:.3f}'.format(count, i, target[count], float(output)))\n",
    "            else:\n",
    "                count_2 = 0\n",
    "                for o in output:\n",
    "                    print('{}. {} ---- {} ----> {:.3f}'.format(count, i, target[count][count_2], float(o)))\n",
    "                    count_2 += 1 \n",
    "            count += 1\n",
    "    \n",
    "    def feed_forward(self, input):\n",
    "        \"\"\"the feed forward function\"\"\"\n",
    "        self.layers_output = []\n",
    "        \n",
    "        for index in range(self.n_layers):\n",
    "            if index == 0:\n",
    "                z = np.dot(input, self.weights[index].T) + self.biases[index]\n",
    "                self.layers_output.append(self.sigmoid(z))\n",
    "            else: \n",
    "                z = np.dot(self.layers_output[index -1], self.weights[index].T) + self.biases[index]\n",
    "                self.layers_output.append(self.sigmoid(z))\n",
    "        \n",
    "        return self.layers_output\n",
    "    \n",
    "    def back_propagation(self, input, target, trainingRate = 0.2):\n",
    "        \"\"\"the back_propagation function\"\"\"\n",
    "        l_errors = []\n",
    "        \n",
    "        #feed forward\n",
    "        self.feed_forward(input)\n",
    "        \n",
    "        # compute l_errors \n",
    "        for index in reversed(range(self.n_layers)):\n",
    "            if index == self.n_layers - 1:\n",
    "                sig_prim = self.derivative(self.layers_output[index])\n",
    "                output_delta = -(target - self.layers_output[index])*sig_prim\n",
    "                l_errors.append(output_delta)\n",
    "            else:\n",
    "                hidden_delta = np.dot(l_errors[-1], self.weights[index+1])\n",
    "                l_errors.append(hidden_delta*self.derivative(self.layers_output[index]))\n",
    "        \n",
    "        l_errors = l_errors[::-1]\n",
    "        self.layers_output.insert(0, input)\n",
    "        \n",
    "        # new biases and weights\n",
    "        for index in range(self.n_layers ):    \n",
    "            multiply = np.multiply(l_errors[index].T, self.layers_output[index])            \n",
    "            self.weights[index] = self.weights[index] - trainingRate*multiply\n",
    "            self.biases[index] = self.biases[index] - trainingRate*l_errors[index]\n",
    "        \n",
    "        return (self.weights, self.biases)\n",
    "    \n",
    "    def main(self, epochs, trainingRate, input, target):\n",
    "        err_vector = []\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            count = 0\n",
    "            err = 0\n",
    "            \n",
    "            for x in input:\n",
    "                \n",
    "                #back propagation\n",
    "                self.back_propagation(x, target[count], trainingRate)\n",
    "                \n",
    "                #net error\n",
    "                err+= self.net_error(target[count], self.layers_output[-1][0])\n",
    "                \n",
    "                count +=1\n",
    "            err_vector.append(err / input.shape[0])\n",
    "            \n",
    "        #graph error\n",
    "        self.graph_error(err_vector)\n",
    "        \n",
    "        #testings patterns\n",
    "        self.testing_patterns(input, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"XOR learning\"\"\"\n",
    "\n",
    "my_mlp = MLP([2, 2, 1])\n",
    "#my_mlp.main(8000, 0.5, np.array([[0,0],[0,1],[1,0],[1,1]]), np.array([0,1,1,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Iris dataset learning\"\"\"\n",
    "\n",
    "#get the iris dataset\n",
    "def get_dataset():\n",
    "    f = open(\"./iris_data/iris.data\")\n",
    "    \n",
    "    lines = f.readlines()\n",
    "    f.close()\n",
    "    \n",
    "    input = []\n",
    "    output = []\n",
    "    \n",
    "    for line in lines:\n",
    "        if(len(line) > 1):\n",
    "            x_0, x_1, x_2, x_3, y = line.replace('\\n','').split(',')\n",
    "            input.append([float(x_0),float(x_1),float(x_2),float(x_3)])\n",
    "            \n",
    "            if y == 'Iris-setosa':\n",
    "                output.append([1,0,0])\n",
    "            if y == 'Iris-versicolor':\n",
    "                output.append([0,1,0])\n",
    "            if y == 'Iris-virginica':\n",
    "                output.append([0,0,1])\n",
    "    return (input, output)\n",
    "\n",
    "\n",
    "my_mlp = MLP([4, 2, 3, 3])\n",
    "input, output = get_dataset()\n",
    "\n",
    "#my_mlp.main(500, 0.5, np.array(input), np.array(output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Credit approval dataset\"\"\"\n",
    "\n",
    "#get the iris dataset\n",
    "def get_credit_approval():\n",
    "    f = open(\"./iris_data/iris.data\")\n",
    "    \n",
    "    lines = f.readlines()\n",
    "    f.close()\n",
    "    \n",
    "    input = []\n",
    "    output = []\n",
    "    \n",
    "    for line in lines:\n",
    "        if(len(line) > 1):\n",
    "            x_0, x_1, x_2, x_3, y = line.replace('\\n','').split(',')\n",
    "            input.append([float(x_0),float(x_1),float(x_2),float(x_3)])\n",
    "            \n",
    "            if y == 'Iris-setosa':\n",
    "                output.append([1,0,0])\n",
    "            if y == 'Iris-versicolor':\n",
    "                output.append([0,1,0])\n",
    "            if y == 'Iris-virginica':\n",
    "                output.append([0,0,1])\n",
    "    return (input, output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
