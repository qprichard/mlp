{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====== MLP result ======\n",
      "Pat:    t:    out:\n",
      "0. [0 0] ---- 0 ----> 1.000\n",
      "1. [0 1] ---- 1 ----> 1.000\n",
      "2. [1 0] ---- 1 ----> 1.000\n",
      "3. [1 1] ---- 0 ----> 1.000\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib qt\n",
    "\n",
    "class MLP:\n",
    "    \"\"\"Class defining a neural network using back propagation\"\"\"\n",
    "    \n",
    "    def __init__(self, layers):\n",
    "        \"\"\"layers is initialized as a list(input_layer, ...hidden_layers..., output_layers)\"\"\"\n",
    "        self.n_layers = len(layers) - 1\n",
    "        self.layers = layers\n",
    "        self.initialize_weights()\n",
    "        self.actual_output = 0\n",
    "        \n",
    "    def initialize_weights(self):\n",
    "        \"\"\"generate weights and biases for hidden layers \n",
    "        in a standard gaussian distribution  mean 0 deviation 1\"\"\"\n",
    "        self.biases = [np.random.randn(1, y) for y in self.layers[1:]]\n",
    "        self.weights = [np.random.randn(y, x) for x, y in zip(self.layers[:-1], self.layers[1:])]\n",
    "    \n",
    "    def sigmoid(self, x, Derivative=False):\n",
    "        \"\"\"The sigmoid function and its derivative\"\"\"\n",
    "        if not Derivative:\n",
    "            return 1 / (1 + np.exp(-x))    \n",
    "        else:\n",
    "            out = self.sigmoid(x)\n",
    "            return out * (1 - out)\n",
    "    \n",
    "    def net_error(self, tar, out):\n",
    "        \"\"\"compute the network error\"\"\"\n",
    "        err = 0.5*np.power(tar - out, 2)\n",
    "        \n",
    "        return err\n",
    "    \n",
    "    def graph_error(self, err_vector):\n",
    "        \"\"\"display graphical error\"\"\"\n",
    "        plt.figure(0)\n",
    "        plt.plot(err_vector)\n",
    "        plt.xlabel(\"Epochs\")\n",
    "        plt.ylabel(\"Error\")\n",
    "        plt.title(\"Back-Propagation algortihm\")\n",
    "        plt.show()\n",
    "    \n",
    "    def testing_patterns(self, input, target):\n",
    "        print('====== MLP result ======')\n",
    "        print('Pat:    t:    out:')\n",
    "        count = 0\n",
    "        for i in input:\n",
    "            output = self.feed_forward(input)[0][0]\n",
    "            \n",
    "            if not hasattr(target[count], '__len__'):\n",
    "                print('{}. {} ---- {} ----> {:.3f}'.format(count, i, target[count], float(output)))\n",
    "            else:\n",
    "                count_2 = 0\n",
    "                for o in output:\n",
    "                    print('{}. {} ---- {} ----> {:.3f}'.format(count, i, target[count][count_2], float(o)))\n",
    "                    count_2 += 1 \n",
    "            count += 1\n",
    "    \n",
    "    def feed_forward(self, input):\n",
    "        \"\"\"the feed forward function\"\"\"\n",
    "        self.layers_output = []\n",
    "        \n",
    "        for index in range(self.n_layers):\n",
    "            if index == 0:\n",
    "                z = np.dot(input, self.weights[index].T) + self.biases[index]\n",
    "                self.layers_output.append(self.sigmoid(z))\n",
    "            else: \n",
    "                \n",
    "                z = np.dot(self.layers_output[index -1], self.weights[index].T) + self.biases[index]\n",
    "                self.layers_output.append(self.sigmoid(z))\n",
    "        \n",
    "        return self.layers_output[-1]\n",
    "    \n",
    "    def back_propagation(self, input, target, trainingRate = 0.2):\n",
    "        \"\"\"the back_propagation function\"\"\"\n",
    "        l_errors = []\n",
    "        \n",
    "        #feed forward\n",
    "        self.feed_forward(input)\n",
    "        \n",
    "        # compute l_errors \n",
    "        for index in reversed(range(self.n_layers)):\n",
    "            if index == self.n_layers - 1:\n",
    "                output_delta = -(target - self.layers_output[index])*self.sigmoid(self.layers_output[index], True)\n",
    "                l_errors.append(output_delta)\n",
    "            else:\n",
    "                hidden_delta = np.dot(l_errors[-1], self.weights[index+1])\n",
    "                l_errors.append(hidden_delta*self.sigmoid(self.layers_output[index], True))\n",
    "        \n",
    "        l_errors = l_errors[::-1]\n",
    "        \n",
    "        # new biases and weights\n",
    "        for index in range(self.n_layers):\n",
    "            multiply = trainingRate*np.multiply(l_errors[index], self.layers_output[index])\n",
    "            self.weights[index] = self.weights[index] - multiply.T\n",
    "            self.biases[index] = self.biases[index] - trainingRate*l_errors[index]\n",
    "    \n",
    "    def main(self, epochs, trainingRate, input, target):\n",
    "        err_vector = []\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            count = 0\n",
    "            err = 0\n",
    "            \n",
    "            for x in input:\n",
    "                \n",
    "                #bacj propagation\n",
    "                self.back_propagation(x, target[count], trainingRate)\n",
    "                \n",
    "                #net error\n",
    "                \n",
    "                err+= self.net_error(target[count], self.layers_output[-1])\n",
    "                \n",
    "                count +=1\n",
    "            err_vector.append(err[0][0] / input.shape[0])\n",
    "            \n",
    "        #graph error\n",
    "        self.graph_error(err_vector)\n",
    "        \n",
    "        #testings patterns\n",
    "        self.testing_patterns(input, target)\n",
    "        \n",
    "        \n",
    "my_mlp = MLP([2, 1])\n",
    "\n",
    "my_mlp.main(3000, 0.5, np.array([[0,0],[0,1],[1,0],[1,1]]), np.array([0,1,1,0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
